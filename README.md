# Conditional VAE Convolucional sobre MNIST

Este proyecto implementa un **Variational Autoencoder Condicionado (CVAE)** con arquitecturas convolucionales para el dataset MNIST, utilizando **PyTorch Lightning** para facilitar el entrenamiento y la gesti√≥n del ciclo de vida del modelo.

---

## üìã Requisitos

- Python 3.8 o superior
- GPU con soporte CUDA (opcional, pero recomendado)
- pip

Contenido de `requeriments.txt`:
```
torch
pytorch-lightning
torchvision
numpy
matplotlib
```

---

## ‚öôÔ∏è Instalaci√≥n

1. Clona el repositorio:
   ```bash
git clone https://github.com/iamam07/modelos-generativos.git
cd tu-repo
```

2. Instala dependencias:
   ```bash
pip install -r requeriments.txt
```

---

## üöÄ Uso

Abre la notebook situada en el repositorio (por ejemplo `CVAE_MNIST.ipynb`) con tu entorno de Jupyter (Jupyter Lab, Jupyter Notebook) o desde VS Code si prefieres trabajar con notebooks ah√≠.

1. Navega a la carpeta del proyecto:
   ```bash
   cd tu-repo
   ```
2. Abre Jupyter Lab:  
   ```bash
   jupyter lab
   ```
3. En el explorador de Jupyter, abre `CVAE_MNIST.ipynb`.
4. Ejecuta las celdas secuencialmente (Cell ‚Üí Run All) para instalar dependencias, preparar datos, entrenar el modelo y visualizar resultados.

---

## üìê Estructura del C√≥digo

1. **Importaci√≥n y configuraci√≥n**
   - Instalaci√≥n de requerimientos y ajustes de `multiprocessing` y precisi√≥n de botones de matriz.

2. **`MNISTDataModule`**
   - Hereda de `LightningDataModule` para descargar y preparar datos de MNIST.
   - Genera `train_dataloader` y `val_dataloader` con `DataLoader` de PyTorch.

3. **Encoder Convolucional (`CVAEEncoderConv`)**
   - Tres capas `Conv2d` con normales por batch y activaci√≥n ReLU.
   - C√°lculo din√°mico de la dimensi√≥n aplanada usando `get_flattened_size_and_shape`.
   - Producci√≥n de `mu` y `logvar` para el espacio latente.

4. **Decoder Convolucional (`CVAEDecoderConv`)**
   - Tres capas `ConvTranspose2d` inversas con BatchNorm y ReLU.
   - Reconstrucci√≥n de la imagen final con `sigmoid`.

5. **LightningModule (`ConvCVAE`)**
   - Combina encoder y decoder.
   - Implementa el m√©todo de reparametrizaci√≥n, la funci√≥n de p√©rdida (BCE + KL), y pasos de entrenamiento/validaci√≥n.
   - Configura el optimizador Adam.

6. **Entrenamiento y visualizaci√≥n**
   - Funci√≥n `train_model` que entrena para cada learning rate y muestra grillas de im√°genes generadas.

7. **Generaci√≥n condicionada**
   - Funciones `generate_images` y `generate_for_digit` para producir muestras latentes condicionadas a cada d√≠gito.

---

## üìä Resultados esperados

- Durante el entrenamiento, el script mostrar√° en cada √©poca la p√©rdida de entrenamiento y validaci√≥n.
- Tras el entrenamiento, generar√° y visualizar√° grillas de 10√ó10 im√°genes para cada d√≠gito 0‚Äì9.
- Permite generar muestras adicionales para un d√≠gito espec√≠fico mediante `generate_for_digit`.

---

## ü§ù Contribuciones

1. Haz un fork del proyecto
2. Crea una rama (`git checkout -b feature/nueva-funcionalidad`)
3. Realiza tus cambios y haz commit (`git commit -m "A√±ade..."`)
4. Haz push a tu rama (`git push origin feature/nueva-funcionalidad`)
5. Abre un Pull Request para revisi√≥n

---

## üìÑ Licencia

Este proyecto est√° bajo la licencia MIT. Consulta el archivo `LICENSE` para m√°s detalles.

